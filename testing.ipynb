{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0cdca9-f565-420e-aa6b-a42eee62a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a628700c-9b09-4323-a921-e02c6e0d3575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301829"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "tokens = enc.encode(text)\n",
    "padding_token = enc.encode(\"\\n\")[0]\n",
    "n_vocab = enc.n_vocab\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2e1558c3-bdf7-4dca-8103-ea18f26b0ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "n_embd = 32\n",
    "n_heads = int(n_embd / 4)\n",
    "n_blocks = 4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c264ae9-e218-4f96-95ab-7ffe26577195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3dc0d13a-d71f-4a89-91cb-a42309b42b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [1, 2,3 ,4,5, 6, 7]\n",
    "test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "08ddfe6f-6ea4-4c28-8acf-8826ac0db6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 9])\n",
      "torch.Size([6707, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(tokens, dtype=torch.long)\n",
    "n = int(0.9*data.shape[0])\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0918d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "864c55ee-bbec-49c0-8c45-0fc9ab086ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, block_size, n_embd, head_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones((block_size, block_size))))\n",
    "    def forward(self, x):\n",
    "        _, T, C = x.shape\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        wei = q @ k.mT * C**-0.5\n",
    "        \n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3a5c0d2a-5acb-4025-b8e6-7a3065b562cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, block_size, n_embd, n_heads):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.n_embd = n_embd\n",
    "        self.n_heads = n_heads\n",
    "        assert (self.n_embd % self.n_heads) == 0\n",
    "        self.head_size = n_embd // self.n_heads\n",
    "        self.heads = nn.ModuleList([Head(self.block_size, self.n_embd, self.head_size) for _ in range(self.n_heads)])\n",
    "        self.projection = nn.Linear(n_embd, n_embd)\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        x = self.projection(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d433fbde-2638-4679-9412-d7890bcc0a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.n_embd = n_embd\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd * 4, n_embd),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "387d398b-2560-4b6d-bc18-00152d5fce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, block_size, n_embd, n_heads):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.n_embd = n_embd\n",
    "        self.n_heads = n_heads\n",
    "        self.self_attention = MultiHeadAttention(self.block_size, self.n_embd, self.n_heads)\n",
    "        self.feedforward = FeedForward(self.n_embd)\n",
    "        self.ln1 = nn.LayerNorm(self.n_embd)\n",
    "        self.ln2 = nn.LayerNorm(self.n_embd)\n",
    "    def forward(self, x):\n",
    "        x = x + self.self_attention(self.ln1(x))\n",
    "        x = x + self.feedforward(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f8b4caf0-44a2-49ac-a217-81e7f4f9e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, block_size, n_vocab, n_embd, n_heads, n_blocks):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.n_vocab = n_vocab\n",
    "        self.n_embd = n_embd\n",
    "        self.n_heads = n_heads\n",
    "        self.n_blocks = n_blocks\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.n_vocab, self.n_embd)\n",
    "        self.positional_embedding = nn.Embedding(self.block_size, self.n_embd)\n",
    "        self.blocks = nn.Sequential(*[TransformerBlock(self.block_size, self.n_embd, self.n_heads) for _ in range(self.n_blocks)])\n",
    "        self.ln = nn.LayerNorm(self.n_embd)\n",
    "        self.lm_head = nn.Linear(self.n_embd, self.n_vocab)\n",
    "    def forward(self, idx, targets=None):\n",
    "        tok_embd = self.embedding(idx)\n",
    "        pos_embd = self.positional_embedding(torch.arange(0, self.block_size))\n",
    "        x = tok_embd + pos_embd\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.lm_head(x)\n",
    "        loss = None\n",
    "        \n",
    "        # if targets is None:\n",
    "        #     pass\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2fa7b999-c7e0-47a4-810c-b97f001e30a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2706, -0.1236,  1.1974,  ...,  0.4005, -0.2644, -0.2203],\n",
       "         [-0.4871, -0.3172, -0.0730,  ..., -0.4406,  1.2822,  0.0958],\n",
       "         [-0.2143, -0.2342, -0.5432,  ..., -1.0173,  0.4597,  0.1983],\n",
       "         ...,\n",
       "         [-0.8043, -0.4944,  0.0324,  ...,  0.2026,  1.5352, -0.0804],\n",
       "         [-0.3575,  1.1241, -0.3230,  ...,  0.1771,  0.5986, -0.2469],\n",
       "         [-0.3133, -0.0172,  0.2017,  ..., -0.6932, -0.0298,  0.1927]],\n",
       "\n",
       "        [[ 0.6229, -0.7065,  0.4110,  ...,  0.6928, -0.8343,  0.5626],\n",
       "         [-1.1165, -0.6047, -0.7571,  ..., -0.4478,  1.3511,  0.3368],\n",
       "         [-0.3604, -0.6866, -1.1339,  ..., -0.3051,  0.6021,  0.3928],\n",
       "         ...,\n",
       "         [-0.9221, -1.2039, -0.5934,  ...,  0.0033,  0.5720, -0.0851],\n",
       "         [-0.1702,  0.8628,  0.1382,  ...,  0.0643,  0.3970, -0.3166],\n",
       "         [-0.4408, -0.1644, -0.3611,  ..., -0.4050, -1.4617,  0.2096]],\n",
       "\n",
       "        [[ 0.6229, -0.7065,  0.4110,  ...,  0.6928, -0.8343,  0.5626],\n",
       "         [-0.4555, -0.1284,  0.2218,  ..., -0.6990,  0.7210, -0.2187],\n",
       "         [ 0.2407,  0.2085, -0.2002,  ..., -1.0584,  0.7668, -0.1507],\n",
       "         ...,\n",
       "         [-1.0194, -0.6468, -0.2340,  ..., -0.1121,  1.1893,  0.1159],\n",
       "         [-0.7808,  0.5882, -1.0232,  ...,  0.3109, -0.0725, -0.5471],\n",
       "         [ 0.4470, -0.2414,  0.7310,  ...,  0.0171,  0.3406,  0.4572]],\n",
       "\n",
       "        [[ 0.7414, -0.1995, -0.1450,  ..., -0.8301, -1.1426, -0.0441],\n",
       "         [-0.0236,  0.6252,  0.0667,  ..., -0.2990,  2.6285,  0.2751],\n",
       "         [-0.2740, -0.5316, -0.8432,  ..., -0.3720,  0.8661,  0.2283],\n",
       "         ...,\n",
       "         [-1.6135, -0.9407, -0.2709,  ..., -0.4707,  1.6861,  0.0287],\n",
       "         [-0.3264,  0.8056,  0.4727,  ...,  0.2054, -0.0217, -0.1184],\n",
       "         [ 0.4305, -0.8313, -0.7582,  ..., -0.3724, -0.6725,  0.0844]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(block_size, n_vocab, n_embd, n_heads, n_blocks)\n",
    "model(batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04d3030a-bd99-4086-966e-816cab40160f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5451, 47317,   512, 10438,   584, 10570,   904,  4726],\n",
       "        [   11,  6865,   757,  6604,   382,  2460,   512, 96945],\n",
       "        [   11,  6604,   382,  5451, 47317,   512,  2675,   527],\n",
       "        [  682, 20250,  4856,   311,  2815,  1109,   311,  2138]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5734b68b-3a3b-46d7-b971-8fea90f29522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 256])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.randn((4, 8, 128)), torch.randn((4, 8, 128))], dim=-1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
